name: CNNbLSTM_Extended
save_dir: saved/CNNbLSTM/
seed: 1234
target_devices: [0]

arch:
  type: CNNbLSTM_Extended
  args:
    init_n_channels: 1280
    out_channels: 32
    cnn_layers: 2
    kernel_size: [129, 257]
    padding: [64, 128]
    n_hidden: 64
    dropout: 0.5
    lstm_layers: 2
    embedding_args:
      arch: roberta_large
      dropout: 0.0
      attention_dropout: 0.0
      activation_dropout: 0.0
      ffn_embed_dim: 5120
      layers: 33
      attention_heads: 20
      embed_dim: 1280
      max_positions: 1024
      learned_pos: true
      activation_fn: gelu
      use_bert_init: true
      normalize_before: true
      preact_normalize: true
      normalize_after: true
      token_dropout: true
      no_seed_provided: false
      pooler_activation_fn: 'tanh'
      pooler_dropout: 0.0
      checkpoint_transformer_block: false
      untie_weights_roberta: false
    embedding_pretrained: "./models/esm1b_t33_650M_UR50S.pt"

data_loader:
  type: NSPDataLoader
  args:
    train_path: [data/nsp2/training_data/Train_HHblits_small.npz]
    test_path: [data/nsp2/training_data/CASP12_HHblits.npz, 
                data/nsp2/training_data/CB513_HHblits.npz, 
                data/nsp2/training_data/TS115_HHblits.npz]
    dataset_loader: NSPDataOnlyEncoding
    batch_size: 15
    nworkers: 2
    shuffle: true
    validation_split: 0.05

loss: multi_task_extended

metrics:
  metric_ss8: 0
  metric_ss3_from_ss8: 0
  metric_dis_mcc: 1
  metric_dis_fpr: 1
  metric_rsa: 2
  metric_rsa: 3
  metric_asa: 2
  metric_phi: 4
  metric_psi: 5

optimizer:
  type: Adam
  args:
    lr: 0.0005
    weight_decay: 0

training:
  early_stop: 3
  epochs: 100
  monitor: min val_loss
  save_period: 999
  tensorboard: true

lr_scheduler: 
  type: null

augmentation:
  type: sparse_token
  args: {}